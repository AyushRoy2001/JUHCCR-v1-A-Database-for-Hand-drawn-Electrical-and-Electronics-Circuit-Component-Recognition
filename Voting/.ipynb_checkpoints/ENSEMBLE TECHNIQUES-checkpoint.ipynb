{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8604b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.backend as Kback\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2861f52",
   "metadata": {},
   "source": [
    "# Loading dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b953655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = K.preprocessing.image.ImageDataGenerator(rescale = 1./255)   \n",
    "\n",
    "test_dataset  = test_datagen.flow_from_directory(directory = 'D:/RESEARCH/Circuit component recognition/test',\n",
    "                                                   target_size = (160,160),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   subset = 'training',\n",
    "                                                   shuffle=False,\n",
    "                                                   batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89285025",
   "metadata": {},
   "source": [
    "# The three best models for voting (snapshot 1,2 and DenseNet121_CBAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9638698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = Kback.sum(Kback.round(Kback.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = Kback.sum(Kback.round(Kback.clip(y_true, 0, 1)))\n",
    "    predicted_positives = Kback.sum(Kback.round(Kback.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + Kback.epsilon())\n",
    "    recall = true_positives / (possible_positives + Kback.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+Kback.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "model0 = K.models.load_model(\"snapshot_model_5.h5\", custom_objects={\"f1_score\": f1_score})\n",
    "model1 = K.models.load_model(\"snapshot_model_2.h5\", custom_objects={\"f1_score\": f1_score})\n",
    "model2 = K.models.load_model(\"snapshot_model_3.h5\", custom_objects={\"f1_score\": f1_score})\n",
    "model3 = K.models.load_model(\"snapshot_model_4.h5\", custom_objects={\"f1_score\": f1_score})\n",
    "model4 = K.models.load_model(\"snapshot_model_1.h5\", custom_objects={\"f1_score\": f1_score})\n",
    "model_cbam = K.models.load_model(\"densenet121_cbam.hdf5\", custom_objects={\"f1_score\": f1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5514ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/2209102674.py:4: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_0 = model0.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n",
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/2209102674.py:8: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_1 = model1.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n",
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/2209102674.py:12: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_2 = model2.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n",
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/2209102674.py:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_3 = model3.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n",
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/2209102674.py:20: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_4 = model4.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    }
   ],
   "source": [
    "y_label = np.asarray(test_dataset.classes)\n",
    "y_label = y_label.astype('int')\n",
    "\n",
    "Y_pred_0 = model0.predict_generator(test_dataset, 1157)\n",
    "y_pred_0 = np.argmax(Y_pred_0, axis=1)\n",
    "y_pred_0 = y_pred_0.astype('int')\n",
    "\n",
    "Y_pred_1 = model1.predict_generator(test_dataset, 1157)\n",
    "y_pred_1 = np.argmax(Y_pred_1, axis=1)\n",
    "y_pred_1 = y_pred_1.astype('int')\n",
    "\n",
    "Y_pred_2 = model2.predict_generator(test_dataset, 1157)\n",
    "y_pred_2 = np.argmax(Y_pred_2, axis=1)\n",
    "y_pred_2 = y_pred_2.astype('int')\n",
    "\n",
    "Y_pred_3 = model3.predict_generator(test_dataset, 1157)\n",
    "y_pred_3 = np.argmax(Y_pred_3, axis=1)\n",
    "y_pred_3 = y_pred_3.astype('int')\n",
    "\n",
    "Y_pred_4 = model4.predict_generator(test_dataset, 1157)\n",
    "y_pred_4 = np.argmax(Y_pred_4, axis=1)\n",
    "y_pred_4 = y_pred_4.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47923c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroy8\\AppData\\Local\\Temp/ipykernel_33296/1173042140.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred_cbam = model0.predict_generator(test_dataset, 1157)\n",
      "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1157 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    }
   ],
   "source": [
    "Y_pred_cbam = model0.predict_generator(test_dataset, 1157)\n",
    "y_pred_cbam = np.argmax(Y_pred_cbam, axis=1)\n",
    "y_pred_cbam = y_pred_cbam.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863f425",
   "metadata": {},
   "source": [
    "#### Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1929b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_max(arr1,arr2,arr3):\n",
    "    arr = []\n",
    "    for i in range(0,2000):\n",
    "        if arr1[i] == arr2[i] or arr1[i] == arr3[i] or arr1[i] == arr2[i] == arr3[i]:\n",
    "            arr.append(arr1[i])\n",
    "        elif arr2[i] == arr3[i]:\n",
    "            arr.append(arr2[i])\n",
    "        else:\n",
    "            arr.append(arr1[i])\n",
    "    arr = np.asarray(arr)\n",
    "    arr = arr.astype('int')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5def251",
   "metadata": {},
   "source": [
    "#### Weighted voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c477f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_weighted(arr1,arr2,arr3):\n",
    "    arr = []\n",
    "    for i in range(0,2000):\n",
    "        arr.append(0.4*arr1[i]+0.3*arr2[i]+0.3*arr3[i])\n",
    "    arr = np.asarray(arr)\n",
    "    arr = arr.astype('int')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d0595",
   "metadata": {},
   "source": [
    "#### Groupwise weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545fca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_group_weighted(arr1,arr2,arr3,arr4,arr5):\n",
    "    arr = []\n",
    "    for i in range(0,2000):\n",
    "        a = 0.4*arr1[i]+(0.2*arr2[i]+0.1*arr5[i])+(0.2*arr3[i]+0.1*arr4[i])\n",
    "        arr.append(a)\n",
    "    arr = np.asarray(arr)\n",
    "    arr = arr.astype('int')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98982fac",
   "metadata": {},
   "source": [
    "#### Mean weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f0a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_mean(Y_pred_1,Y_pred_2,Y_pred_3):\n",
    "    Y_pred = 0.4*Y_pred_1+0.3*Y_pred_2+0.3*Y_pred_3\n",
    "    Y_pred = np.log(Y_pred)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_pred = y_pred.astype('int')\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a6137",
   "metadata": {},
   "source": [
    "#### Gompertz ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68964576",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = []\n",
    "for i in range(0,2000):\n",
    "    stacked.append([Y_pred_0[i],Y_pred_1[i],Y_pred_2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533cd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3, 20)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(stacked).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90a9043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([9.9986386e-01, 2.5423926e-06, 1.2696629e-08, 4.5923616e-11,\n",
      "       3.5061429e-10, 4.8712383e-08, 1.9183911e-07, 1.3140139e-10,\n",
      "       3.3648316e-08, 6.1577841e-09, 6.6157394e-05, 3.5967540e-05,\n",
      "       8.7441849e-09, 9.0958729e-10, 2.3594687e-10, 4.7182291e-10,\n",
      "       3.4775405e-12, 1.8194713e-08, 3.0932180e-05, 2.2671465e-07],\n",
      "      dtype=float32), array([9.97427166e-01, 2.28996396e-05, 2.13008161e-06, 1.51133928e-09,\n",
      "       9.22386434e-09, 3.78384766e-06, 6.64181653e-06, 1.96376732e-07,\n",
      "       4.62536218e-06, 1.22397307e-06, 1.66598277e-03, 7.41306867e-04,\n",
      "       1.58715670e-06, 1.26661035e-07, 3.76361609e-09, 7.55932028e-09,\n",
      "       1.22920536e-08, 9.53654933e-07, 1.18640935e-04, 2.67414771e-06],\n",
      "      dtype=float32), array([9.98484552e-01, 1.83669090e-05, 6.45345381e-07, 1.07099760e-10,\n",
      "       2.67518674e-09, 3.50620354e-07, 1.82946474e-06, 4.18144133e-08,\n",
      "       8.88728607e-07, 2.04755068e-07, 9.75441188e-04, 4.12857044e-04,\n",
      "       2.17481414e-07, 1.10582015e-08, 5.03696918e-10, 1.96820715e-09,\n",
      "       2.11613416e-09, 2.21777199e-07, 1.03233855e-04, 1.21542257e-06],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(stacked[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7d38b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def fuzzy_rank(CF, top):\n",
    "    R_L = np.zeros(CF.shape)\n",
    "    for i in range(CF.shape[0]):\n",
    "        for j in range(CF.shape[1]):\n",
    "            for k in range(CF.shape[2]):\n",
    "                R_L[i][j][k] = 1 - math.exp(-math.exp(-2.0*CF[i][j][k]))  #Gompertz Function\n",
    "    \n",
    "    K_L = 0.632*np.ones(shape = R_L.shape) #initiate all values as penalty values\n",
    "    for i in range(R_L.shape[0]):\n",
    "        for sample in range(R_L.shape[1]):\n",
    "            for k in range(top):\n",
    "                a = R_L[i][sample]\n",
    "                idx = np.where(a==np.partition(a, k)[k])\n",
    "                #if sample belongs to top 'k' classes, R_L =R_L, else R_L = penalty value\n",
    "                K_L[i][sample][idx] = R_L[i][sample][idx]\n",
    "\n",
    "    return K_L\n",
    "\n",
    "def CFS_func(CF, K_L):\n",
    "    H = CF.shape[0] #no. of classifiers\n",
    "    for f in range(CF.shape[0]):\n",
    "        for i in range(CF.shape[1]):\n",
    "            idx = np.where(K_L[f][i] == 0.632)\n",
    "            CF[f][i][idx] = 0\n",
    "    CFS = 1 - np.sum(CF,axis=0)/H\n",
    "    return CFS\n",
    "\n",
    "def Gompertz(boom):\n",
    "    top = 2\n",
    "    L = 0 #Number of classifiers\n",
    "    for arg in boom:\n",
    "        L += 1\n",
    "\n",
    "#     num_classes = np.asarray(boom).shape[1]\n",
    "#     CF = np.zeros(shape = (L,np.asarray(arg).shape[0], np.asarray(arg).shape[1]))\n",
    "\n",
    "#     for i, arg in enumerate(boom):\n",
    "#         CF[:][:][i] = boom\n",
    "    CF = np.asarray(boom)\n",
    "\n",
    "    R_L = fuzzy_rank(CF, top) #R_L is with penalties\n",
    "    \n",
    "    RS = np.sum(R_L, axis=0)\n",
    "    CFS = CFS_func(CF, R_L)\n",
    "    FS = RS*CFS\n",
    "\n",
    "    predictions = np.argmin(FS,axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aea7ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gompertz(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00b9ae",
   "metadata": {},
   "source": [
    "# Metrics of the voting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5c3f3",
   "metadata": {},
   "source": [
    "#### Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_max(y_pred_0, y_pred_1, y_pred_2)\n",
    "\n",
    "#Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_label, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm,display_labels=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20'])\n",
    "\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Testing accuracy:\")\n",
    "print(accuracy_score(y_label, y_pred))\n",
    "#F1_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Testing F1-score\")\n",
    "print(f1_score(y_label, y_pred, average = 'macro'))\n",
    "#Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Testing Precision:\")\n",
    "print(precision_score(y_label, y_pred, average = 'macro'))\n",
    "#Recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Testing Recall:\")\n",
    "print(recall_score(y_label, y_pred, average = 'macro'))\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d38812",
   "metadata": {},
   "source": [
    "#### Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_weighted(y_pred_0, y_pred_1, y_pred_2)\n",
    "\n",
    "#Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_label, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm,display_labels=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20'])\n",
    "\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Testing accuracy:\")\n",
    "print(accuracy_score(y_label, y_pred))\n",
    "#F1_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Testing F1-score\")\n",
    "print(f1_score(y_label, y_pred, average = 'macro'))\n",
    "#Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Testing Precision:\")\n",
    "print(precision_score(y_label, y_pred, average = 'macro'))\n",
    "#Recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Testing Recall:\")\n",
    "print(recall_score(y_label, y_pred, average = 'macro'))\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968a8ce",
   "metadata": {},
   "source": [
    "#### Groupwise Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_group_weighted(y_pred_0, y_pred_1, y_pred_2, y_pred_3, y_pred_4)\n",
    "\n",
    "#Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_label, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm,display_labels=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20'])\n",
    "\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Testing accuracy:\")\n",
    "print(accuracy_score(y_label, y_pred))\n",
    "#F1_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Testing F1-score\")\n",
    "print(f1_score(y_label, y_pred, average = 'macro'))\n",
    "#Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Testing Precision:\")\n",
    "print(precision_score(y_label, y_pred, average = 'macro'))\n",
    "#Recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Testing Recall:\")\n",
    "print(recall_score(y_label, y_pred, average = 'macro'))\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a45ba9",
   "metadata": {},
   "source": [
    "#### Mean Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e15a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_mean(Y_pred_0, Y_pred_1, Y_pred_2)\n",
    "\n",
    "#Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_label, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm,display_labels=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20'])\n",
    "\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Testing accuracy:\")\n",
    "print(accuracy_score(y_label, y_pred))\n",
    "#F1_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Testing F1-score\")\n",
    "print(f1_score(y_label, y_pred, average = 'macro'))\n",
    "#Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Testing Precision:\")\n",
    "print(precision_score(y_label, y_pred, average = 'macro'))\n",
    "#Recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Testing Recall:\")\n",
    "print(recall_score(y_label, y_pred, average = 'macro'))\n",
    "\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
